// Request/Response types for the inference server's endpoints.
//
// Run `pipenv run build` to build this (or see the README).

syntax = "proto3";

package inference;

// We're going to represent tensors as a flat array + the tensor's dimensions +
// its data type.
message Tensor {
    // From the tensorflow.js [docs](js.tensorflow.org/api/1.1.2/#tensor):
    //   - dtype ('float32'|'int32'|'bool'|'complex64'|'string')
    //
    // We'll use a oneof with flat arrays of different types to give us both the
    // flat array and the data type.

    message FloatArray {
        repeated float array = 1;
    }

    message IntArray {
        repeated int32 array = 1;
    }

    message BoolArray {
        repeated bool array = 1;
    }

    // TODO: Add support!
    message Complex {
        int64 real = 1;
        int64 imaginary = 2;
    }

    message ComplexArray {
        repeated Complex array = 1;
    }

    message StringArray {
        repeated string array = 1;
    }

    // Flat array + data type:
    oneof flat_array {
        FloatArray floats = 1;
        IntArray ints = 2;
        BoolArray bools = 3;
        ComplexArray complex_nums = 4;
        StringArray strings = 5;
    }

    // Dimensions:
    repeated uint64 dimensions = 6;
}

message Model {
    // TODO!!
}

message Error {
    enum Kind {
        // TODO!!
        OTHER = 0;

        INVALID_TENSOR_MESSAGE = 1;
        MISSHAPEN_TENSOR = 2;
        TENSOR_CONVERSION_ERROR = 3;
        TENSOR_TYPE_ERROR = 4;
        UNKNOWN_TENSOR_ERROR = 10;

        INVALID_HANDLE_ERROR = 11;
        MODEL_REGISTER_ERROR = 12;
        MODEL_STORE_FULL_ERROR = 13;
        MODEL_ACQUIRE_ERROR = 14;   // TODO!
        MODEL_CONVERSION_ERROR = 15; // TODO!
        MODEL_LOAD_ERROR = 16;
        UNKNOWN_MODEL_ERROR = 20;

        NCORE_NOT_PRESENT = 21;
        INVALID_DELEGATE_LIBRARY = 22;
        UNKNOWN_NCORE_ERROR = 23;
    }

    Kind kind = 1;
    string message = 2;
}

message Metrics {
    int64 time_to_execute = 1; // in ms (TODO!)
    string trace = 2;
}

message ModelHandle {
    int64 id = 1;
}

// LoadModelRequest = Model
// LoadModelResponse = oneof { ModelHandle, Error }
// InferenceRequest = { ModelHandle, Tensor }
// InferenceResponse = oneof { Tensor, Error }

message LoadModelRequest {
    Model model = 1;
}

message LoadModelResponse {
    oneof response {
        ModelHandle handle = 1;
        Error error = 2;
    }
}

message InferenceRequest {
    ModelHandle handle = 1;
    Tensor tensor = 2;
}

message InferenceResponse {
    oneof response {
        Tensor tensor = 1;
        Error error = 2;
    }

    // TODO: not sure if this should be dijoint from error
    Metrics metrics = 3;
}
